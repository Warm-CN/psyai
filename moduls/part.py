import streamlit as st
from openai import OpenAI
import random, time


# æ€ç»´æ•´ç†æ‘˜è¦å‡½æ•°
def summarize_history(history, summarizer):
    messages = [{"role": "system", "content": "è¯·å°†ä»¥ä¸‹å¯¹è¯å†…å®¹æ€»ç»“ä¸ºä¸€æ®µç®€çŸ­çš„èƒŒæ™¯è¯´æ˜ï¼Œç”¨äºåç»­ç»§ç»­å¯¹è¯ï¼š"}]
    messages += history

    response = summarizer.chat.completions.create(
        model="moonshot-v1-8k",
        messages=messages,
        temperature=0.3,
    )
    return response.choices[0].message.content.strip()


# é»˜è®¤æ€è€ƒæç¤ºè¯­
thinking_messages = [
    "ï¼ˆæˆ‘åœ¨è®¤çœŸæƒ³ä½ è¯´çš„è¿™äº›å‘¢ï¼Œç¨ç­‰æˆ‘ä¸€ä¸‹ğŸ’­ï¼‰",
    "ï¼ˆè®©æˆ‘æƒ³ä¸€æƒ³æ€ä¹ˆé™ªä½ è¯´è¯´è¿™ä»¶äº‹...ğŸŒ¿ï¼‰",
    "ï¼ˆæˆ‘åœ¨æ•´ç†æ€ç»ªä¸­ï¼Œå¸Œæœ›èƒ½ç»™ä½ æ¸©æŸ”çš„å›åº”ğŸ’—ï¼‰",
    "ï¼ˆæˆ‘æ¥äº†ï¼Œæ­£åœ¨é…é…¿å›åº”ä¸­å‘¢ï½âœ¨ï¼‰",
    "ï¼ˆç­‰æˆ‘ä¸€ä¸‹ï¼Œæˆ‘æƒ³å¥½å¥½åœ°é™ªä½ è¯´è¯´è¿™ä¸ª...ğŸŒ¸ï¼‰"
]


# æ ¸å¿ƒèŠå¤©å‡½æ•°
def run_chat_interface(
        page_title: str,
        page_icon: str,
        welcome_title: str,
        welcome_message: str,
        first_message: str,
        system_prompt: str,
        session_key: str,
        custom_css: str,
        avatar_user: str = "avatars/user.jpg",
        avatar_assistant: str = "avatars/assistant.jpg",
):
    # åŠ è½½å¯†é’¥
    api_key = st.secrets["GLM_FLASH_API_KEY"]
    client = OpenAI(
        api_key=api_key,  # åœ¨è¿™é‡Œå¡«å…¥ä½ çš„ API key
        base_url="https://open.bigmodel.cn/api/paas/v4/",
    )

    st.set_page_config(page_title=page_title, page_icon=page_icon, layout="centered")
    st.markdown(custom_css, unsafe_allow_html=True)

    st.markdown(f"## {welcome_title}")
    st.markdown(f"<div style='color: #666; font-size: 17px;'>{welcome_message}</div>", unsafe_allow_html=True)

    # åˆå§‹åŒ–æ¶ˆæ¯é˜Ÿåˆ—
    if session_key not in st.session_state:
        st.session_state[session_key] = [
            {"role": "system", "content": system_prompt}
        ]

    messages = st.session_state[session_key]

    # å¦‚æœåªæœ‰ç³»ç»Ÿæ¶ˆæ¯ï¼Œå‘é€æ¬¢è¿è¯­
    if len(messages) == 1:
        messages.append({"role": "assistant", "content": first_message})

    for message in messages[1:]:
        avatar = avatar_user if message["role"] == "user" else avatar_assistant
        css_class = message["role"]
        with st.chat_message(message["role"], avatar=avatar):
            st.markdown(
                f"<div class='stChatMessage {css_class}'>{message['content']}</div>",
                unsafe_allow_html=True
            )

    if prompt := st.chat_input("â€¦â€¦"):
        messages.append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar=avatar_user):
            st.markdown(f"<div class='stChatMessage user'>{prompt}</div>", unsafe_allow_html=True)

        with st.chat_message("assistant", avatar=avatar_assistant):
            placeholder = st.empty()
            full_response = ""

            thinking_message = random.choice(thinking_messages)
            placeholder.markdown(
                f"<div class='stChatMessage assistant'>{thinking_message}</div>",
                unsafe_allow_html=True
            )

            system_msg = messages[0]
            non_system_msgs = messages[1:]

            if len(non_system_msgs) > 15:
                summary = summarize_history(non_system_msgs[:-10], client)
                dynamic_system = {
                    "role": "system",
                    "content": system_msg["content"] + "\n\nä»¥ä¸‹æ˜¯ä½ å’Œç”¨æˆ·ä¹‹é—´çš„ç®€è¦å¯¹è¯èƒŒæ™¯ï¼š\n" + summary
                }
                send_messages = [dynamic_system] + non_system_msgs[-10:]
            else:
                send_messages = [system_msg] + non_system_msgs[-15:]

            stream = client.chat.completions.create(
                model="glm-4-flash",
                messages=send_messages,
                stream=True,
                temperature=0.7,
            )

            for chunk in stream:
                if chunk.choices[0].delta.content:
                    full_response += chunk.choices[0].delta.content
                    placeholder.markdown(
                        f"<div class='stChatMessage assistant'>{full_response}</div>",
                        unsafe_allow_html=True
                    )
                    if len(full_response) % 8 == 0:
                        time.sleep(0.05)

            messages.append({"role": "assistant", "content": full_response})
